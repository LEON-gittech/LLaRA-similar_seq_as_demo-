{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaModel, AutoModelForCausalLM, LlamaForCausalLM, GenerationConfig, LlamaConfig, AutoTokenizer\n",
    "# 全局加载LLaMA-2-7B模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"/mnt/bn/data-tns-live-llm/leon/datasets/Llama-2-7b-hf\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer: Optional[LlamaTokenizer] = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "# 设置pad_token为eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"Tokenizer loaded.\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model: Optional[LlamaForCausalLM] = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16, output_hidden_states=True)\n",
    "try: model.to(device)\n",
    "except : pass\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_dtw_distance(embedding_seq1, embedding_seq2):\n",
    "#     # 将向量调整为二维数组，以便 fastdtw 正确处理\n",
    "#     embedding_seq1 = embedding_seq1.reshape(-1, 1)\n",
    "#     embedding_seq2 = embedding_seq2.reshape(-1, 1)\n",
    "#     distance, path = fastdtw(embedding_seq1, embedding_seq2, dist=euclidean)\n",
    "#     return distance\n",
    "\n",
    "# def calculate_similarity(df):\n",
    "#     movie_embeddings = get_movie_embeddings(df['movie_names_only'].tolist())\n",
    "#     df['movie_embeddings'] = list(movie_embeddings)\n",
    "#     embeddings = np.stack(df['movie_embeddings'].values)\n",
    "    \n",
    "#     most_similar_indices = []\n",
    "#     for i, embedding_seq1 in enumerate(embeddings):\n",
    "#         min_distance = float('inf')\n",
    "#         most_similar_index = -1\n",
    "#         for j, embedding_seq2 in enumerate(embeddings):\n",
    "#             if i != j:\n",
    "#                 distance = calculate_dtw_distance(embedding_seq1, embedding_seq2)\n",
    "#                 if distance < min_distance:\n",
    "#                     min_distance = distance\n",
    "#                     most_similar_index = j\n",
    "#         most_similar_indices.append(most_similar_index)\n",
    "    \n",
    "#     df['most_similar_seq_index'] = most_similar_indices\n",
    "#     df['most_similar_seq'] = df['most_similar_seq_index'].apply(lambda idx: df.at[idx, 'seq'])\n",
    "#     return df\n",
    "\n",
    "# def add_most_similar_seq_next(df, movie_dict):\n",
    "#     df['most_similar_seq_next'] = df['next'].iloc[df['most_similar_seq_indexs']].values\n",
    "#     df['most_similar_seq_name'] = df['most_similar_seqs'].apply(lambda x: [movie_dict.get(item[0], \"Unknown\") for item in x])\n",
    "#     df['most_similar_seq_next_name'] = df['most_similar_seq_next'].apply(lambda x: movie_dict.get(x[0], \"Unknown\"))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "def load_movie_dict(item_file):\n",
    "    item_df = pd.read_csv(item_file, sep='|', header=None, encoding='latin-1', usecols=[0, 1])\n",
    "    item_df.columns = ['movie_id', 'movie_title']\n",
    "    movie_dict = dict(zip(item_df['movie_id'], item_df['movie_title']))\n",
    "    return movie_dict\n",
    "\n",
    "def map_movie_names_only(seq, movie_dict):\n",
    "    return [movie_dict[id] if id in movie_dict else id for (id, rating) in seq]\n",
    "\n",
    "def extract_sequences(df, movie_dict):\n",
    "    df['movie_names_only'] = df['seq'].apply(lambda x: map_movie_names_only(x, movie_dict))\n",
    "    df['seq_only'] = df['seq'].apply(lambda x: [id for (id, rating) in x])\n",
    "    return df\n",
    "\n",
    "def get_movie_embeddings(movie_list):\n",
    "    embeddings = []\n",
    "    max_length = 512  # 设定一个合理的最大长度\n",
    "    for movies in tqdm(movie_list):\n",
    "        movie_string = \" \".join(str(movie) for movie in movies)\n",
    "        inputs = tokenizer(movie_string, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            movie_embedding = outputs.hidden_states[-1].mean(dim=1).squeeze().cpu()\n",
    "        embeddings.append(movie_embedding)\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "def get_topk_similar_indices(similarity_scores, topK):\n",
    "    print(similarity_scores.shape)\n",
    "    indices = np.argsort(-np.array(similarity_scores.to(torch.float32)))\n",
    "    print(indices.shape)\n",
    "    print(indices[-5:])\n",
    "    topk_indices = np.ones((indices.shape[0], topK))\n",
    "    for i,indice in enumerate(indices):\n",
    "        tmp = indice[indice!=i]\n",
    "        topk_indices[i] = tmp[:topK] # 获取每个向量最相似的topK个索引, 不包含他自己\n",
    "    # topk_indices = topk_indices.to(torch.int)\n",
    "    print(topk_indices.shape)\n",
    "    return topk_indices\n",
    "\n",
    "def get_topK_candidate(df, topK=10):\n",
    "    embeddings = get_movie_embeddings(df['movie_names_only'].tolist())\n",
    "    # df['movie_embeddings'] = list(movie_embeddings)\n",
    "    # embeddings = np.stack(df['movie_embeddings'].values)\n",
    "    similarity_scores = embeddings @ embeddings.T\n",
    "    # 对于每个嵌入向量，找到最相似的topK个嵌入向量的索引\n",
    "    most_similar_indices = np.array(get_topk_similar_indices(similarity_scores, topK)).tolist()\n",
    "    print(type(most_similar_indices))\n",
    "    # 将索引信息添加到DataFrame中\n",
    "    df['most_similar_seq_index'] = [json.dumps(most_similar_idxs) for most_similar_idxs in most_similar_indices]\n",
    "    # 根据索引获取最相似的序列\n",
    "    df['most_similar_seq'] = df['most_similar_seq_indexs'].apply(lambda idxs: [df.at[idx, 'seq'] for idx in json.loads(idxs)])\n",
    "    return df\n",
    "\n",
    "def add_most_similar_seq_next(df, movie_dict):\n",
    "    df['most_similar_seq_next'] = df['most_similar_seq_index'].apply(lambda idxs: [df.at[idx, 'next'] for idx in json.loads(idxs)])\n",
    "    df['most_similar_seq_name'] = df['most_similar_seq'].apply(lambda x: [[movie_dict.get(item[0], \"Unknown\") for item in items] for items in x])\n",
    "    df['most_similar_seq_next_name'] = df['most_similar_seq_next'].apply(lambda x: [movie_dict.get(item[0], \"Unknown\") for item in x])\n",
    "    return df\n",
    "\n",
    "def save_data(df, output_file_path):\n",
    "    df.to_pickle(output_file_path)\n",
    "\n",
    "def process_data(file_path, item_file, output_file_path):\n",
    "    data = load_data(file_path)\n",
    "    movie_dict = load_movie_dict(item_file)\n",
    "    df = extract_sequences(data, movie_dict)\n",
    "    df = get_topK_candidate(df)\n",
    "    df = add_most_similar_seq_next(df, movie_dict)\n",
    "    save_data(df, output_file_path)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/train_data.df'\n",
    "item_file = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/u.item'\n",
    "output_file_path = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/similar_train_data.df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(file_path)\n",
    "movie_dict = load_movie_dict(item_file)\n",
    "df = extract_sequences(data, movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68388 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 68388/68388 [19:08<00:00, 59.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([68388, 68388])\n",
      "(68388, 68388)\n",
      "[[43369 60202 16659 ... 28484 33981 45316]\n",
      " [35108 43369 43368 ... 28484 33981 45316]\n",
      " [35108  3430 43371 ... 33981 28484 45316]\n",
      " [43368 43369 43371 ... 28484 33981 45316]\n",
      " [27329 35108 42728 ... 28484 33981 45316]]\n",
      "(68388, 10)\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "topK = 10\n",
    "embeddings = get_movie_embeddings(df['movie_names_only'].tolist())\n",
    "# df['movie_embeddings'] = list(movie_embeddings)\n",
    "# embeddings = np.stack(df['movie_embeddings'].values)\n",
    "similarity_scores = embeddings @ embeddings.T\n",
    "# 对于每个嵌入向量，找到最相似的topK个嵌入向量的索引\n",
    "most_similar_indices = np.array(get_topk_similar_indices(similarity_scores, topK)).tolist()\n",
    "print(type(most_similar_indices))\n",
    "# 将索引信息添加到DataFrame中\n",
    "df['most_similar_seq_index'] = [json.dumps(most_similar_idxs) for most_similar_idxs in most_similar_indices]\n",
    "# 根据索引获取最相似的序列\n",
    "df['most_similar_seq'] = df['most_similar_seq_index'].apply(lambda idxs: [df.at[idx, 'seq'] for idx in json.loads(idxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dict = load_movie_dict(item_file)\n",
    "tmp = add_most_similar_seq_next(df, movie_dict)\n",
    "save_data(tmp, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/Val_data.df'\n",
    "item_file = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/u.item'\n",
    "output_file_path = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/similar_val_data.df'\n",
    "data = load_data(file_path)\n",
    "movie_dict = load_movie_dict(item_file)\n",
    "df = extract_sequences(data, movie_dict)\n",
    "topK = 10\n",
    "embeddings = get_movie_embeddings(df['movie_names_only'].tolist())\n",
    "# df['movie_embeddings'] = list(movie_embeddings)\n",
    "# embeddings = np.stack(df['movie_embeddings'].values)\n",
    "similarity_scores = embeddings @ embeddings.T\n",
    "# 对于每个嵌入向量，找到最相似的topK个嵌入向量的索引\n",
    "most_similar_indices = np.array(get_topk_similar_indices(similarity_scores, topK)).tolist()\n",
    "print(type(most_similar_indices))\n",
    "# 将索引信息添加到DataFrame中\n",
    "df['most_similar_seq_index'] = [json.dumps(most_similar_idxs) for most_similar_idxs in most_similar_indices]\n",
    "# 根据索引获取最相似的序列\n",
    "df['most_similar_seq'] = df['most_similar_seq_index'].apply(lambda idxs: [df.at[idx, 'seq'] for idx in json.loads(idxs)])\n",
    "movie_dict = load_movie_dict(item_file)\n",
    "tmp = add_most_similar_seq_next(df, movie_dict)\n",
    "save_data(tmp, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/Test_data.df'\n",
    "item_file = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/u.item'\n",
    "output_file_path = '/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/similar_test_data.df'\n",
    "data = load_data(file_path)\n",
    "movie_dict = load_movie_dict(item_file)\n",
    "df = extract_sequences(data, movie_dict)\n",
    "topK = 10\n",
    "embeddings = get_movie_embeddings(df['movie_names_only'].tolist())\n",
    "# df['movie_embeddings'] = list(movie_embeddings)\n",
    "# embeddings = np.stack(df['movie_embeddings'].values)\n",
    "similarity_scores = embeddings @ embeddings.T\n",
    "# 对于每个嵌入向量，找到最相似的topK个嵌入向量的索引\n",
    "most_similar_indices = np.array(get_topk_similar_indices(similarity_scores, topK)).tolist()\n",
    "print(type(most_similar_indices))\n",
    "# 将索引信息添加到DataFrame中\n",
    "df['most_similar_seq_index'] = [json.dumps(most_similar_idxs) for most_similar_idxs in most_similar_indices]\n",
    "# 根据索引获取最相似的序列\n",
    "df['most_similar_seq'] = df['most_similar_seq_index'].apply(lambda idxs: [df.at[idx, 'seq'] for idx in json.loads(idxs)])\n",
    "movie_dict = load_movie_dict(item_file)\n",
    "tmp = add_most_similar_seq_next(df, movie_dict)\n",
    "save_data(tmp, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hoodlum (1997)', 'Mother (1996)', 'Fierce Creatures (1997)', \"Ulee's Gold (1997)\", 'Hellraiser: Bloodline (1996)', 'Last Supper, The (1995)', 'Snow White and the Seven Dwarfs (1937)', 'Maximum Risk (1996)', 'White Squall (1996)', 'Home for the Holidays (1995)']\n"
     ]
    }
   ],
   "source": [
    "i=10\n",
    "print(tmp[\"movie_names_only\"][i][:tmp[\"len_seq\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp[\"most_similar_seq_name\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = [\" \".join(names) for names in tmp[\"most_similar_seq_name\"][10][:10]]\n",
    "print(len(movie_list))\n",
    "movie_lists = \"\"\n",
    "for i,name in enumerate(movie_list):\n",
    "    movie_lists += f\"Watch History {i+1}: {name} \\n\"\n",
    "print(movie_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_movie = \" \".join(tmp[\"movie_names_only\"][i][:tmp[\"len_seq\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are a system that recommends movies based on viewing history. Please evaluate the similarity between each watch history in the candidate list and the single target watch history. Rate the similarity on a scale from 1 to 10 between , where 1 is not similar at all and 10 is very similar.\n",
    "\n",
    "Candidate Watch History:\n",
    "{movie_lists}\n",
    "\n",
    "Target Watch History:\n",
    "{target_movie}\n",
    "\n",
    "Please output the similarity ratings in JSON format. The output should only contain the JSON object with similarity scores, without any additional text. Output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are an intelligent movie recommendation assistant. The sequences below represent the watching histories of users. Ranking the candidate sequences based on their similarity to the target sequence. Similarity is defined by both the semantic content of the movies and the order in which they are watched.\n",
    "\n",
    "[target sequence: {target_movie}]\n",
    "\n",
    "[candidate sequences:\n",
    "{movie_lists}]\n",
    "Rank the 10 sequences above based on their similarity to the target sequence, considering both the semantic content of the movies and their order. The sequences should be listed in descending order using identifiers. The most similar sequences should be listed first. The output format should be [] > [], e.g., [user 1] > [user 2]. Only respond with the ranking results, do not say any word or explain.\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "try: output = model.generate(input[\"input_ids\"].cuda(), temperature=0.1).cpu()[0]\n",
    "except: output = model.generate(input[\"input_ids\"], temperature=0.1).cpu()[0]\n",
    "output = tokenizer.decode(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看 similar_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f1783281c70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tiger/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     seq  len_seq       next  \\\n",
      "0      [(1682, 0), (1682, 0), (1682, 0), (1682, 0), (...        1   (299, 5)   \n",
      "1      [(299, 5), (1682, 0), (1682, 0), (1682, 0), (1...        1   (321, 5)   \n",
      "2      [(299, 5), (321, 5), (1682, 0), (1682, 0), (16...        2   (290, 4)   \n",
      "3      [(299, 5), (321, 5), (290, 4), (1682, 0), (168...        3   (297, 3)   \n",
      "4      [(299, 5), (321, 5), (290, 4), (297, 3), (1682...        4   (590, 4)   \n",
      "...                                                  ...      ...        ...   \n",
      "68383  [(180, 5), (918, 5), (297, 5), (256, 4), (6, 4...       10   (454, 4)   \n",
      "68384  [(918, 5), (297, 5), (256, 4), (6, 4), (123, 5...       10   (146, 4)   \n",
      "68385  [(297, 5), (256, 4), (6, 4), (123, 5), (992, 4...       10  (1006, 4)   \n",
      "68386  [(256, 4), (6, 4), (123, 5), (992, 4), (762, 3...       10     (0, 5)   \n",
      "68387  [(6, 4), (123, 5), (992, 4), (762, 3), (272, 3...       10    (14, 4)   \n",
      "\n",
      "                                        movie_names_only  \\\n",
      "0      [Scream of Stone (Schrei aus Stein) (1991), Sc...   \n",
      "1      [Hoodlum (1997), Scream of Stone (Schrei aus S...   \n",
      "2      [Hoodlum (1997), Mother (1996), Scream of Ston...   \n",
      "3      [Hoodlum (1997), Mother (1996), Fierce Creatur...   \n",
      "4      [Hoodlum (1997), Mother (1996), Fierce Creatur...   \n",
      "...                                                  ...   \n",
      "68383  [Apocalypse Now (1979), City of Angels (1998),...   \n",
      "68384  [City of Angels (1998), Ulee's Gold (1997), Wh...   \n",
      "68385  [Ulee's Gold (1997), When the Cats Away (Chacu...   \n",
      "68386  [When the Cats Away (Chacun cherche son chat) ...   \n",
      "68387  [Shanghai Triad (Yao a yao yao dao waipo qiao)...   \n",
      "\n",
      "                                                seq_only  \\\n",
      "0      [1682, 1682, 1682, 1682, 1682, 1682, 1682, 168...   \n",
      "1      [299, 1682, 1682, 1682, 1682, 1682, 1682, 1682...   \n",
      "2      [299, 321, 1682, 1682, 1682, 1682, 1682, 1682,...   \n",
      "3      [299, 321, 290, 1682, 1682, 1682, 1682, 1682, ...   \n",
      "4      [299, 321, 290, 297, 1682, 1682, 1682, 1682, 1...   \n",
      "...                                                  ...   \n",
      "68383   [180, 918, 297, 256, 6, 123, 992, 762, 272, 474]   \n",
      "68384   [918, 297, 256, 6, 123, 992, 762, 272, 474, 454]   \n",
      "68385   [297, 256, 6, 123, 992, 762, 272, 474, 454, 146]   \n",
      "68386  [256, 6, 123, 992, 762, 272, 474, 454, 146, 1006]   \n",
      "68387    [6, 123, 992, 762, 272, 474, 454, 146, 1006, 0]   \n",
      "\n",
      "                                  most_similar_seq_index  \\\n",
      "0      [9070.0, 22226.0, 51919.0, 9086.0, 27481.0, 22...   \n",
      "1      [0.0, 54907.0, 34865.0, 18585.0, 66551.0, 2538...   \n",
      "2      [8626.0, 0.0, 62931.0, 22192.0, 30272.0, 46986...   \n",
      "3      [0.0, 64105.0, 29793.0, 64141.0, 18253.0, 3989...   \n",
      "4      [40833.0, 51428.0, 8627.0, 8626.0, 63956.0, 58...   \n",
      "...                                                  ...   \n",
      "68383  [43369.0, 60202.0, 16659.0, 3430.0, 35108.0, 4...   \n",
      "68384  [35108.0, 43369.0, 43368.0, 16659.0, 60202.0, ...   \n",
      "68385  [35108.0, 3430.0, 43371.0, 16659.0, 43369.0, 4...   \n",
      "68386  [43368.0, 43369.0, 43371.0, 16659.0, 35108.0, ...   \n",
      "68387  [27329.0, 35108.0, 42728.0, 16659.0, 51617.0, ...   \n",
      "\n",
      "                                        most_similar_seq  \\\n",
      "0      [[(1682, 0), (1682, 0), (1682, 0), (1682, 0), ...   \n",
      "1      [[(1682, 0), (1682, 0), (1682, 0), (1682, 0), ...   \n",
      "2      [[(874, 4), (1682, 0), (1682, 0), (1682, 0), (...   \n",
      "3      [[(1682, 0), (1682, 0), (1682, 0), (1682, 0), ...   \n",
      "4      [[(55, 3), (76, 3), (1682, 0), (1682, 0), (168...   \n",
      "...                                                  ...   \n",
      "68383  [[(640, 4), (478, 5), (610, 5), (482, 5), (177...   \n",
      "68384  [[(55, 5), (693, 4), (86, 3), (522, 4), (10, 3...   \n",
      "68385  [[(55, 5), (693, 4), (86, 3), (522, 4), (10, 3...   \n",
      "68386  [[(514, 5), (640, 4), (478, 5), (610, 5), (482...   \n",
      "68387  [[(27, 5), (466, 4), (199, 5), (22, 3), (392, ...   \n",
      "\n",
      "                                   most_similar_seq_next  \\\n",
      "0      [(312, 5), (886, 5), (287, 5), (257, 4), (285,...   \n",
      "1      [(299, 5), (301, 5), (257, 4), (330, 3), (285,...   \n",
      "2      [(327, 3), (299, 5), (257, 4), (257, 5), (332,...   \n",
      "3      [(299, 5), (267, 4), (126, 4), (267, 5), (268,...   \n",
      "4      [(212, 4), (747, 4), (305, 4), (327, 3), (303,...   \n",
      "...                                                  ...   \n",
      "68383  [(264, 5), (447, 3), (468, 3), (609, 4), (1166...   \n",
      "68384  [(1166, 4), (264, 5), (426, 5), (468, 3), (447...   \n",
      "68385  [(1166, 4), (609, 4), (185, 3), (468, 3), (264...   \n",
      "68386  [(426, 5), (264, 5), (185, 3), (468, 3), (1166...   \n",
      "68387  [(63, 5), (1166, 4), (654, 3), (468, 3), (6, 5...   \n",
      "\n",
      "                                   most_similar_seq_name  \\\n",
      "0      [[Scream of Stone (Schrei aus Stein) (1991), S...   \n",
      "1      [[Scream of Stone (Schrei aus Stein) (1991), S...   \n",
      "2      [[Career Girls (1997), Scream of Stone (Schrei...   \n",
      "3      [[Scream of Stone (Schrei aus Stein) (1991), S...   \n",
      "4      [[Professional, The (1994), Carlito's Way (199...   \n",
      "...                                                  ...   \n",
      "68383  [[Cook the Thief His Wife & Her Lover, The (19...   \n",
      "68384  [[Professional, The (1994), Casino (1995), Rem...   \n",
      "68385  [[Professional, The (1994), Casino (1995), Rem...   \n",
      "68386  [[Annie Hall (1977), Cook the Thief His Wife &...   \n",
      "68387  [[Bad Boys (1995), Red Rock West (1992), Bridg...   \n",
      "\n",
      "                              most_similar_seq_next_name  \n",
      "0      [Midnight in the Garden of Good and Evil (1997...  \n",
      "1      [Hoodlum (1997), In & Out (1997), Men in Black...  \n",
      "2      [Cop Land (1997), Hoodlum (1997), Men in Black...  \n",
      "3      [Hoodlum (1997), unknown, Spitfire Grill, The ...  \n",
      "4      [Unbearable Lightness of Being, The (1988), Be...  \n",
      "...                                                  ...  \n",
      "68383  [Mimic (1997), Carrie (1976), Rudy (1993), Fat...  \n",
      "68384  [Love & Human Remains (1993), Mimic (1997), Tr...  \n",
      "68385  [Love & Human Remains (1993), Father of the Br...  \n",
      "68386  [Transformers: The Movie, The (1986), Mimic (1...  \n",
      "68387  [Santa Clause, The (1994), Love & Human Remain...  \n",
      "\n",
      "[68388 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"/mnt/bn/data-tns-live-llm/leon/recom/LLaRA-similar_seq_as_demo-/data/ref/movielens/similar_train_data.df\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
