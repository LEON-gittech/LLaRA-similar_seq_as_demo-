{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bbfd5c-09aa-46c3-9115-df601cfa5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b6dc005-996c-4edd-b88f-484009de39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"/workspace/LLaRA/data/ref/movielens/similar_train_data.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3854f90-1cc7-4c21-b9ff-4c25d366a1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>len_seq</th>\n",
       "      <th>next</th>\n",
       "      <th>movie_names_only</th>\n",
       "      <th>seq_only</th>\n",
       "      <th>movie_embeddings</th>\n",
       "      <th>most_similar_seq_index</th>\n",
       "      <th>most_similar_seq</th>\n",
       "      <th>most_similar_seq_next</th>\n",
       "      <th>most_similar_seq_name</th>\n",
       "      <th>most_similar_seq_next_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(1682, 0), (1682, 0), (1682, 0), (1682, 0), (...</td>\n",
       "      <td>1</td>\n",
       "      <td>(299, 5)</td>\n",
       "      <td>[Scream of Stone (Schrei aus Stein) (1991), Sc...</td>\n",
       "      <td>[1682, 1682, 1682, 1682, 1682, 1682, 1682, 168...</td>\n",
       "      <td>[0.11899047, 0.15521938, -0.050070673, 0.01224...</td>\n",
       "      <td>72</td>\n",
       "      <td>[(1682, 0), (1682, 0), (1682, 0), (1682, 0), (...</td>\n",
       "      <td>(285, 4)</td>\n",
       "      <td>[Scream of Stone (Schrei aus Stein) (1991), Sc...</td>\n",
       "      <td>Secrets &amp; Lies (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(299, 5), (1682, 0), (1682, 0), (1682, 0), (1...</td>\n",
       "      <td>1</td>\n",
       "      <td>(321, 5)</td>\n",
       "      <td>[Hoodlum (1997), Scream of Stone (Schrei aus S...</td>\n",
       "      <td>[299, 1682, 1682, 1682, 1682, 1682, 1682, 1682...</td>\n",
       "      <td>[0.04874387, 0.10191959, -0.11362585, 0.060890...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[(299, 4), (1682, 0), (1682, 0), (1682, 0), (1...</td>\n",
       "      <td>(22, 5)</td>\n",
       "      <td>[Hoodlum (1997), Scream of Stone (Schrei aus S...</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(299, 5), (321, 5), (1682, 0), (1682, 0), (16...</td>\n",
       "      <td>2</td>\n",
       "      <td>(290, 4)</td>\n",
       "      <td>[Hoodlum (1997), Mother (1996), Scream of Ston...</td>\n",
       "      <td>[299, 321, 1682, 1682, 1682, 1682, 1682, 1682,...</td>\n",
       "      <td>[0.070891894, 0.09061544, -0.047394834, 0.1048...</td>\n",
       "      <td>48729</td>\n",
       "      <td>[(299, 4), (321, 3), (1682, 0), (1682, 0), (16...</td>\n",
       "      <td>(258, 3)</td>\n",
       "      <td>[Hoodlum (1997), Mother (1996), Scream of Ston...</td>\n",
       "      <td>Contact (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(299, 5), (321, 5), (290, 4), (1682, 0), (168...</td>\n",
       "      <td>3</td>\n",
       "      <td>(297, 3)</td>\n",
       "      <td>[Hoodlum (1997), Mother (1996), Fierce Creatur...</td>\n",
       "      <td>[299, 321, 290, 1682, 1682, 1682, 1682, 1682, ...</td>\n",
       "      <td>[0.058338705, 0.0664447, -0.025192026, 0.14220...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(299, 5), (321, 5), (1682, 0), (1682, 0), (16...</td>\n",
       "      <td>(290, 4)</td>\n",
       "      <td>[Hoodlum (1997), Mother (1996), Scream of Ston...</td>\n",
       "      <td>Fierce Creatures (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(299, 5), (321, 5), (290, 4), (297, 3), (1682...</td>\n",
       "      <td>4</td>\n",
       "      <td>(590, 4)</td>\n",
       "      <td>[Hoodlum (1997), Mother (1996), Fierce Creatur...</td>\n",
       "      <td>[299, 321, 290, 297, 1682, 1682, 1682, 1682, 1...</td>\n",
       "      <td>[0.068796314, 0.054079924, -0.012297749, 0.144...</td>\n",
       "      <td>3</td>\n",
       "      <td>[(299, 5), (321, 5), (290, 4), (1682, 0), (168...</td>\n",
       "      <td>(297, 3)</td>\n",
       "      <td>[Hoodlum (1997), Mother (1996), Fierce Creatur...</td>\n",
       "      <td>Ulee's Gold (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  len_seq      next  \\\n",
       "0  [(1682, 0), (1682, 0), (1682, 0), (1682, 0), (...        1  (299, 5)   \n",
       "1  [(299, 5), (1682, 0), (1682, 0), (1682, 0), (1...        1  (321, 5)   \n",
       "2  [(299, 5), (321, 5), (1682, 0), (1682, 0), (16...        2  (290, 4)   \n",
       "3  [(299, 5), (321, 5), (290, 4), (1682, 0), (168...        3  (297, 3)   \n",
       "4  [(299, 5), (321, 5), (290, 4), (297, 3), (1682...        4  (590, 4)   \n",
       "\n",
       "                                    movie_names_only  \\\n",
       "0  [Scream of Stone (Schrei aus Stein) (1991), Sc...   \n",
       "1  [Hoodlum (1997), Scream of Stone (Schrei aus S...   \n",
       "2  [Hoodlum (1997), Mother (1996), Scream of Ston...   \n",
       "3  [Hoodlum (1997), Mother (1996), Fierce Creatur...   \n",
       "4  [Hoodlum (1997), Mother (1996), Fierce Creatur...   \n",
       "\n",
       "                                            seq_only  \\\n",
       "0  [1682, 1682, 1682, 1682, 1682, 1682, 1682, 168...   \n",
       "1  [299, 1682, 1682, 1682, 1682, 1682, 1682, 1682...   \n",
       "2  [299, 321, 1682, 1682, 1682, 1682, 1682, 1682,...   \n",
       "3  [299, 321, 290, 1682, 1682, 1682, 1682, 1682, ...   \n",
       "4  [299, 321, 290, 297, 1682, 1682, 1682, 1682, 1...   \n",
       "\n",
       "                                    movie_embeddings  most_similar_seq_index  \\\n",
       "0  [0.11899047, 0.15521938, -0.050070673, 0.01224...                      72   \n",
       "1  [0.04874387, 0.10191959, -0.11362585, 0.060890...                    1003   \n",
       "2  [0.070891894, 0.09061544, -0.047394834, 0.1048...                   48729   \n",
       "3  [0.058338705, 0.0664447, -0.025192026, 0.14220...                       2   \n",
       "4  [0.068796314, 0.054079924, -0.012297749, 0.144...                       3   \n",
       "\n",
       "                                    most_similar_seq most_similar_seq_next  \\\n",
       "0  [(1682, 0), (1682, 0), (1682, 0), (1682, 0), (...              (285, 4)   \n",
       "1  [(299, 4), (1682, 0), (1682, 0), (1682, 0), (1...               (22, 5)   \n",
       "2  [(299, 4), (321, 3), (1682, 0), (1682, 0), (16...              (258, 3)   \n",
       "3  [(299, 5), (321, 5), (1682, 0), (1682, 0), (16...              (290, 4)   \n",
       "4  [(299, 5), (321, 5), (290, 4), (1682, 0), (168...              (297, 3)   \n",
       "\n",
       "                               most_similar_seq_name  \\\n",
       "0  [Scream of Stone (Schrei aus Stein) (1991), Sc...   \n",
       "1  [Hoodlum (1997), Scream of Stone (Schrei aus S...   \n",
       "2  [Hoodlum (1997), Mother (1996), Scream of Ston...   \n",
       "3  [Hoodlum (1997), Mother (1996), Scream of Ston...   \n",
       "4  [Hoodlum (1997), Mother (1996), Fierce Creatur...   \n",
       "\n",
       "  most_similar_seq_next_name  \n",
       "0      Secrets & Lies (1996)  \n",
       "1          Braveheart (1995)  \n",
       "2             Contact (1997)  \n",
       "3    Fierce Creatures (1997)  \n",
       "4         Ulee's Gold (1997)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8794bc05-3b01-4b6d-a2bb-98005af53322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hoodlum (1997)',\n",
       " 'Mother (1996)',\n",
       " 'Fierce Creatures (1997)',\n",
       " \"Ulee's Gold (1997)\",\n",
       " 'Hellraiser: Bloodline (1996)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['movie_names_only'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc7f60e9-d457-49e4-8419-984f969a8088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hoodlum (1997)',\n",
       " 'Mother (1996)',\n",
       " 'Fierce Creatures (1997)',\n",
       " \"Ulee's Gold (1997)\",\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)',\n",
       " 'Scream of Stone (Schrei aus Stein) (1991)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['most_similar_seq_name'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9482b948-90bd-4f23-bfae-662dcb9efa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94 entries, 0 to 93\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   seq                         94 non-null     object\n",
      " 1   len_seq                     94 non-null     int64 \n",
      " 2   next                        94 non-null     object\n",
      " 3   movie_names_only            94 non-null     object\n",
      " 4   seq_only                    94 non-null     object\n",
      " 5   movie_embeddings            94 non-null     object\n",
      " 6   most_similar_seq_index      94 non-null     int64 \n",
      " 7   most_similar_seq            94 non-null     object\n",
      " 8   most_similar_seq_next       94 non-null     object\n",
      " 9   most_similar_seq_name       94 non-null     object\n",
      " 10  most_similar_seq_next_name  94 non-null     object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d3b6a6-7440-46c9-9def-6321b0444240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       seq_length  most_similar_seq_length\n",
      "0              10                       10\n",
      "1              10                       10\n",
      "2              10                       10\n",
      "3              10                       10\n",
      "4              10                       10\n",
      "...           ...                      ...\n",
      "68383          10                       10\n",
      "68384          10                       10\n",
      "68385          10                       10\n",
      "68386          10                       10\n",
      "68387          10                       10\n",
      "\n",
      "[68388 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义安全解析函数\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        return eval(val)\n",
    "    return val\n",
    "\n",
    "# 解析序列\n",
    "def parse_sequences(df):\n",
    "    df['seq'] = df['seq'].apply(safe_eval)\n",
    "    df['most_similar_seq'] = df['most_similar_seq'].apply(safe_eval)\n",
    "    return df\n",
    "\n",
    "# 检查序列长度\n",
    "def check_sequence_lengths(df):\n",
    "    df['seq_length'] = df['seq'].apply(len)\n",
    "    df['most_similar_seq_length'] = df['most_similar_seq'].apply(len)\n",
    "    return df[['seq_length', 'most_similar_seq_length']]\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 加载数据\n",
    "    df=pd.read_pickle(\"/workspace/LLaRA/data/ref/movielens/similar_train_data.df\")\n",
    "    \n",
    "    # 解析序列\n",
    "    df = parse_sequences(df)\n",
    "    \n",
    "    # 检查序列长度\n",
    "    lengths = check_sequence_lengths(df)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(lengths)\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e154d5-3026-4ba7-901b-b228da2016cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(880, 4),\n",
       " (269, 5),\n",
       " (361, 5),\n",
       " (1024, 5),\n",
       " (881, 5),\n",
       " (890, 5),\n",
       " (1242, 5),\n",
       " (1104, 5),\n",
       " (989, 5),\n",
       " (333, 5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"seq\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd198198-61bc-4c3c-8b08-0ce37b5a4d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(323, 4),\n",
       " (1394, 4),\n",
       " (332, 4),\n",
       " (339, 5),\n",
       " (750, 4),\n",
       " (287, 3),\n",
       " (269, 5),\n",
       " (751, 4),\n",
       " (348, 3),\n",
       " (885, 4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"most_similar_seq\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cef80604-02d3-4c61-8f40-4bf2e9c2f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_flagembedding.df\n",
      "       jaccard_similarity  ndcg@1  ndcg@2  ndcg@3  dtw_distance\n",
      "0                1.000000     1.0     0.0     0.0           0.0\n",
      "1                1.000000     1.0     1.0     0.0           0.0\n",
      "2                1.000000     1.0     1.0     1.0           0.0\n",
      "3                0.800000     1.0     1.0     1.0           7.0\n",
      "4                0.833333     1.0     1.0     1.0         293.0\n",
      "...                   ...     ...     ...     ...           ...\n",
      "68383            0.818182     0.0     0.0     0.0         758.0\n",
      "68384            0.818182     0.0     0.0     0.0         758.0\n",
      "68385            0.818182     0.0     0.0     0.0         929.0\n",
      "68386            0.818182     0.0     0.0     0.0         901.0\n",
      "68387            0.818182     0.0     0.0     0.0        1256.0\n",
      "\n",
      "[68388 rows x 5 columns]\n",
      "Average Metrics: {'jaccard_similarity': 0.8076030794396362, 'ndcg@1': 0.14100426975492777, 'ndcg@2': 0.13034450488389776, 'ndcg@3': 0.11861822379659863, 'dtw_distance': 637.1549248406153}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dtw import dtw\n",
    "\n",
    "# 定义安全解析函数\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        return eval(val)\n",
    "    return val\n",
    "\n",
    "# 保留第一个1682，移除其他的函数\n",
    "def remove_extra_padding(seq, pad_value=1682):\n",
    "    found_first_pad = False\n",
    "    cleaned_seq = []\n",
    "    for item in seq:\n",
    "        if item[0] == pad_value:\n",
    "            if not found_first_pad:\n",
    "                cleaned_seq.append(item)\n",
    "                found_first_pad = True\n",
    "        else:\n",
    "            cleaned_seq.append(item)\n",
    "    return cleaned_seq\n",
    "\n",
    "# 计算 DTW 距离\n",
    "def calculate_dtw(seq, most_similar_seq):\n",
    "    seq = remove_extra_padding(seq)\n",
    "    most_similar_seq = remove_extra_padding(most_similar_seq)\n",
    "\n",
    "    # 如果序列为空，返回一个高距离值\n",
    "    if not seq or not most_similar_seq:\n",
    "        return float('inf')\n",
    "\n",
    "    # 提取电影ID\n",
    "    seq_ids = np.array([item[0] for item in seq]).reshape(-1, 1)\n",
    "    most_similar_seq_ids = np.array([item[0] for item in most_similar_seq]).reshape(-1, 1)\n",
    "\n",
    "    # 使用欧氏距离计算 DTW\n",
    "    dist, _, _, _ = dtw(seq_ids, most_similar_seq_ids, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    return dist\n",
    "\n",
    "# 解析序列\n",
    "def parse_sequences(df):\n",
    "    df['seq'] = df['seq'].apply(safe_eval)\n",
    "    df['most_similar_seq'] = df['most_similar_seq'].apply(safe_eval)\n",
    "    return df\n",
    "\n",
    "# 计算Jaccard相似度\n",
    "def calculate_jaccard_similarity(df):\n",
    "    df['jaccard_similarity'] = df.apply(\n",
    "        lambda row: jaccard_similarity([item[0] for item in remove_extra_padding(row['seq'])], \n",
    "                                       [item[0] for item in remove_extra_padding(row['most_similar_seq'])]), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 nDCG\n",
    "def calculate_ndcg(df):\n",
    "    k_list = [1, 2, 3]\n",
    "    for k in k_list:\n",
    "        df[f'ndcg@{k}'] = df.apply(lambda row: ndcg_at_k(row['seq'], row['most_similar_seq'], k), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 DTW 距离\n",
    "def calculate_dtw_for_df(df):\n",
    "    df['dtw_distance'] = df.apply(\n",
    "        lambda row: calculate_dtw(row['seq'], row['most_similar_seq']), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 DCG 和 nDCG 函数\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(seq, most_similar_seq, k):\n",
    "    seq = remove_extra_padding(seq)\n",
    "    most_similar_seq = remove_extra_padding(most_similar_seq)\n",
    "\n",
    "    # 提取电影ID\n",
    "    seq_ids = [item[0] for item in seq]\n",
    "    most_similar_seq_ids = [item[0] for item in most_similar_seq]\n",
    "\n",
    "    if len(seq_ids) < k or len(most_similar_seq_ids) < k:\n",
    "        return 0.0\n",
    "\n",
    "    # 构建相关性列表：位置匹配的为1，否则为0\n",
    "    r = [1 if seq_ids[i] == most_similar_seq_ids[i] else 0 for i in range(k)]\n",
    "\n",
    "    # 计算 DCG 和理想的 DCG\n",
    "    dcg_value = dcg_at_k(r, k)\n",
    "    ideal_r = sorted(r, reverse=True)\n",
    "    ideal_dcg = dcg_at_k(ideal_r, k)\n",
    "\n",
    "    if ideal_dcg == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return dcg_value / ideal_dcg\n",
    "\n",
    "# 定义Jaccard相似度\n",
    "def jaccard_similarity(seq1, seq2):\n",
    "    set1 = set(seq1)\n",
    "    set2 = set(seq2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# 计算平均值\n",
    "def calculate_average_metrics(df):\n",
    "    metrics = ['jaccard_similarity', 'ndcg@1', 'ndcg@2', 'ndcg@3', 'dtw_distance']\n",
    "    averages = {metric: df[metric].mean() for metric in metrics}\n",
    "    return averages\n",
    "\n",
    "# 检查序列长度\n",
    "def check_sequence_lengths(df):\n",
    "    df['seq_length'] = df['seq'].apply(len)\n",
    "    df['most_similar_seq_length'] = df['most_similar_seq'].apply(len)\n",
    "    return df[['seq_length', 'most_similar_seq_length']]\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 加载数据\n",
    "    df = pd.read_pickle('/workspace/LLaRA/data/ref/movielens/train_data_flagembedding.df')\n",
    "\n",
    "    # 解析序列\n",
    "    df = parse_sequences(df)\n",
    "\n",
    "    # 检查序列长度\n",
    "    lengths = check_sequence_lengths(df)\n",
    "   \n",
    "    # 计算Jaccard相似度\n",
    "    df = calculate_jaccard_similarity(df)\n",
    "\n",
    "    # 计算 nDCG\n",
    "    df = calculate_ndcg(df)\n",
    "\n",
    "    # 计算 DTW 距离\n",
    "    df = calculate_dtw_for_df(df)\n",
    "\n",
    "    # 计算平均值\n",
    "    averages = calculate_average_metrics(df)\n",
    "\n",
    "    # 输出结果\n",
    "    print('train_data_flagembedding.df')\n",
    "    print(df[['jaccard_similarity', 'ndcg@1', 'ndcg@2', 'ndcg@3', 'dtw_distance']])\n",
    "    print(\"Average Metrics:\", averages)\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2d762e7-7211-4fdd-b265-9746a838b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_flagembedding.df\n",
      "       jaccard_similarity  ndcg@1  ndcg@2  ndcg@3  dtw_distance\n",
      "0                1.000000     1.0     0.0     0.0           0.0\n",
      "1                1.000000     1.0     1.0     0.0           0.0\n",
      "2                1.000000     1.0     1.0     1.0           0.0\n",
      "3                0.750000     1.0     1.0     1.0          31.0\n",
      "4                0.800000     1.0     1.0     1.0           7.0\n",
      "...                   ...     ...     ...     ...           ...\n",
      "68383            0.818182     0.0     0.0     0.0         758.0\n",
      "68384            0.818182     0.0     0.0     0.0         929.0\n",
      "68385            0.818182     0.0     0.0     0.0         929.0\n",
      "68386            0.250000     1.0     1.0     1.0        1895.0\n",
      "68387            0.176471     1.0     1.0     1.0        2330.0\n",
      "\n",
      "[68388 rows x 5 columns]\n",
      "Average Metrics: {'jaccard_similarity': 0.779372275945109, 'ndcg@1': 0.178993390653331, 'ndcg@2': 0.16831900333391822, 'ndcg@3': 0.15581711510739146, 'dtw_distance': 701.8320319354273}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dtw import dtw\n",
    "\n",
    "# 定义安全解析函数\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        return eval(val)\n",
    "    return val\n",
    "\n",
    "# 保留第一个1682，移除其他的函数\n",
    "def remove_extra_padding(seq, pad_value=1682):\n",
    "    found_first_pad = False\n",
    "    cleaned_seq = []\n",
    "    for item in seq:\n",
    "        if item[0] == pad_value:\n",
    "            if not found_first_pad:\n",
    "                cleaned_seq.append(item)\n",
    "                found_first_pad = True\n",
    "        else:\n",
    "            cleaned_seq.append(item)\n",
    "    return cleaned_seq\n",
    "\n",
    "# 计算 DTW 距离\n",
    "def calculate_dtw(seq, most_similar_seq):\n",
    "    seq = remove_extra_padding(seq)\n",
    "    most_similar_seq = remove_extra_padding(most_similar_seq)\n",
    "\n",
    "    # 如果序列为空，返回一个高距离值\n",
    "    if not seq or not most_similar_seq:\n",
    "        return float('inf')\n",
    "\n",
    "    # 提取电影ID\n",
    "    seq_ids = np.array([item[0] for item in seq]).reshape(-1, 1)\n",
    "    most_similar_seq_ids = np.array([item[0] for item in most_similar_seq]).reshape(-1, 1)\n",
    "\n",
    "    # 使用欧氏距离计算 DTW\n",
    "    dist, _, _, _ = dtw(seq_ids, most_similar_seq_ids, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    return dist\n",
    "\n",
    "# 解析序列\n",
    "def parse_sequences(df):\n",
    "    df['seq'] = df['seq'].apply(safe_eval)\n",
    "    df['most_similar_seq'] = df['most_similar_seq'].apply(safe_eval)\n",
    "    return df\n",
    "\n",
    "# 计算Jaccard相似度\n",
    "def calculate_jaccard_similarity(df):\n",
    "    df['jaccard_similarity'] = df.apply(\n",
    "        lambda row: jaccard_similarity([item[0] for item in remove_extra_padding(row['seq'])], \n",
    "                                       [item[0] for item in remove_extra_padding(row['most_similar_seq'])]), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 nDCG\n",
    "def calculate_ndcg(df):\n",
    "    k_list = [1, 2, 3]\n",
    "    for k in k_list:\n",
    "        df[f'ndcg@{k}'] = df.apply(lambda row: ndcg_at_k(row['seq'], row['most_similar_seq'], k), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 DTW 距离\n",
    "def calculate_dtw_for_df(df):\n",
    "    df['dtw_distance'] = df.apply(\n",
    "        lambda row: calculate_dtw(row['seq'], row['most_similar_seq']), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 DCG 和 nDCG 函数\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(seq, most_similar_seq, k):\n",
    "    seq = remove_extra_padding(seq)\n",
    "    most_similar_seq = remove_extra_padding(most_similar_seq)\n",
    "\n",
    "    # 提取电影ID\n",
    "    seq_ids = [item[0] for item in seq]\n",
    "    most_similar_seq_ids = [item[0] for item in most_similar_seq]\n",
    "\n",
    "    if len(seq_ids) < k or len(most_similar_seq_ids) < k:\n",
    "        return 0.0\n",
    "\n",
    "    # 构建相关性列表：位置匹配的为1，否则为0\n",
    "    r = [1 if seq_ids[i] == most_similar_seq_ids[i] else 0 for i in range(k)]\n",
    "\n",
    "    # 计算 DCG 和理想的 DCG\n",
    "    dcg_value = dcg_at_k(r, k)\n",
    "    ideal_r = sorted(r, reverse=True)\n",
    "    ideal_dcg = dcg_at_k(ideal_r, k)\n",
    "\n",
    "    if ideal_dcg == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return dcg_value / ideal_dcg\n",
    "\n",
    "# 定义Jaccard相似度\n",
    "def jaccard_similarity(seq1, seq2):\n",
    "    set1 = set(seq1)\n",
    "    set2 = set(seq2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# 计算平均值\n",
    "def calculate_average_metrics(df):\n",
    "    metrics = ['jaccard_similarity', 'ndcg@1', 'ndcg@2', 'ndcg@3', 'dtw_distance']\n",
    "    averages = {metric: df[metric].mean() for metric in metrics}\n",
    "    return averages\n",
    "\n",
    "# 检查序列长度\n",
    "def check_sequence_lengths(df):\n",
    "    df['seq_length'] = df['seq'].apply(len)\n",
    "    df['most_similar_seq_length'] = df['most_similar_seq'].apply(len)\n",
    "    return df[['seq_length', 'most_similar_seq_length']]\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 加载数据\n",
    "    df = pd.read_pickle('/workspace/LLaRA/data/ref/movielens/AllMini_train_data.df')\n",
    "\n",
    "    # 解析序列\n",
    "    df = parse_sequences(df)\n",
    "\n",
    "    # 检查序列长度\n",
    "    lengths = check_sequence_lengths(df)\n",
    "   \n",
    "    # 计算Jaccard相似度\n",
    "    df = calculate_jaccard_similarity(df)\n",
    "\n",
    "    # 计算 nDCG\n",
    "    df = calculate_ndcg(df)\n",
    "\n",
    "    # 计算 DTW 距离\n",
    "    df = calculate_dtw_for_df(df)\n",
    "\n",
    "    # 计算平均值\n",
    "    averages = calculate_average_metrics(df)\n",
    "\n",
    "    # 输出结果\n",
    "    print('train_data_flagembedding.df')\n",
    "    print(df[['jaccard_similarity', 'ndcg@1', 'ndcg@2', 'ndcg@3', 'dtw_distance']])\n",
    "    print(\"Average Metrics:\", averages)\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e4fbddd-317d-4ee5-a9a5-e380bd4216a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_flagembedding.df\n",
      "       jaccard_similarity  ndcg@1  ndcg@2  ndcg@3  dtw_distance\n",
      "0                1.000000     1.0     0.0     0.0           0.0\n",
      "1                1.000000     1.0     1.0     0.0           0.0\n",
      "2                1.000000     1.0     1.0     1.0           0.0\n",
      "3                0.600000     1.0     1.0     1.0          32.0\n",
      "4                0.800000     1.0     1.0     1.0           7.0\n",
      "...                   ...     ...     ...     ...           ...\n",
      "68383            0.818182     0.0     0.0     0.0         758.0\n",
      "68384            0.818182     0.0     0.0     0.0         929.0\n",
      "68385            0.818182     0.0     0.0     0.0         929.0\n",
      "68386            0.818182     0.0     0.0     0.0         901.0\n",
      "68387            0.818182     0.0     0.0     0.0        1256.0\n",
      "\n",
      "[68388 rows x 5 columns]\n",
      "Average Metrics: {'jaccard_similarity': 0.8211739555964542, 'ndcg@1': 0.11800315844885068, 'ndcg@2': 0.10974147511259286, 'ndcg@3': 0.09853486662849172, 'dtw_distance': 602.7047727671521}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dtw import dtw\n",
    "\n",
    "# 定义安全解析函数\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        return eval(val)\n",
    "    return val\n",
    "\n",
    "# 保留第一个1682，移除其他的函数\n",
    "def remove_extra_padding(seq, pad_value=1682):\n",
    "    found_first_pad = False\n",
    "    cleaned_seq = []\n",
    "    for item in seq:\n",
    "        if item[0] == pad_value:\n",
    "            if not found_first_pad:\n",
    "                cleaned_seq.append(item)\n",
    "                found_first_pad = True\n",
    "        else:\n",
    "            cleaned_seq.append(item)\n",
    "    return cleaned_seq\n",
    "\n",
    "# 计算 DTW 距离\n",
    "def calculate_dtw(seq, most_similar_seq):\n",
    "    seq = remove_extra_padding(seq)\n",
    "    most_similar_seq = remove_extra_padding(most_similar_seq)\n",
    "\n",
    "    # 如果序列为空，返回一个高距离值\n",
    "    if not seq or not most_similar_seq:\n",
    "        return float('inf')\n",
    "\n",
    "    # 提取电影ID\n",
    "    seq_ids = np.array([item[0] for item in seq]).reshape(-1, 1)\n",
    "    most_similar_seq_ids = np.array([item[0] for item in most_similar_seq]).reshape(-1, 1)\n",
    "\n",
    "    # 使用欧氏距离计算 DTW\n",
    "    dist, _, _, _ = dtw(seq_ids, most_similar_seq_ids, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    return dist\n",
    "\n",
    "# 解析序列\n",
    "def parse_sequences(df):\n",
    "    df['seq'] = df['seq'].apply(safe_eval)\n",
    "    df['most_similar_seq'] = df['most_similar_seq'].apply(safe_eval)\n",
    "    return df\n",
    "\n",
    "# 计算Jaccard相似度\n",
    "def calculate_jaccard_similarity(df):\n",
    "    df['jaccard_similarity'] = df.apply(\n",
    "        lambda row: jaccard_similarity([item[0] for item in remove_extra_padding(row['seq'])], \n",
    "                                       [item[0] for item in remove_extra_padding(row['most_similar_seq'])]), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 nDCG\n",
    "def calculate_ndcg(df):\n",
    "    k_list = [1, 2, 3]\n",
    "    for k in k_list:\n",
    "        df[f'ndcg@{k}'] = df.apply(lambda row: ndcg_at_k(row['seq'], row['most_similar_seq'], k), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 DTW 距离\n",
    "def calculate_dtw_for_df(df):\n",
    "    df['dtw_distance'] = df.apply(\n",
    "        lambda row: calculate_dtw(row['seq'], row['most_similar_seq']), axis=1)\n",
    "    return df\n",
    "\n",
    "# 计算 DCG 和 nDCG 函数\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(seq, most_similar_seq, k):\n",
    "    seq = remove_extra_padding(seq)\n",
    "    most_similar_seq = remove_extra_padding(most_similar_seq)\n",
    "\n",
    "    # 提取电影ID\n",
    "    seq_ids = [item[0] for item in seq]\n",
    "    most_similar_seq_ids = [item[0] for item in most_similar_seq]\n",
    "\n",
    "    if len(seq_ids) < k or len(most_similar_seq_ids) < k:\n",
    "        return 0.0\n",
    "\n",
    "    # 构建相关性列表：位置匹配的为1，否则为0\n",
    "    r = [1 if seq_ids[i] == most_similar_seq_ids[i] else 0 for i in range(k)]\n",
    "\n",
    "    # 计算 DCG 和理想的 DCG\n",
    "    dcg_value = dcg_at_k(r, k)\n",
    "    ideal_r = sorted(r, reverse=True)\n",
    "    ideal_dcg = dcg_at_k(ideal_r, k)\n",
    "\n",
    "    if ideal_dcg == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return dcg_value / ideal_dcg\n",
    "\n",
    "# 定义Jaccard相似度\n",
    "def jaccard_similarity(seq1, seq2):\n",
    "    set1 = set(seq1)\n",
    "    set2 = set(seq2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# 计算平均值\n",
    "def calculate_average_metrics(df):\n",
    "    metrics = ['jaccard_similarity', 'ndcg@1', 'ndcg@2', 'ndcg@3', 'dtw_distance']\n",
    "    averages = {metric: df[metric].mean() for metric in metrics}\n",
    "    return averages\n",
    "\n",
    "# 检查序列长度\n",
    "def check_sequence_lengths(df):\n",
    "    df['seq_length'] = df['seq'].apply(len)\n",
    "    df['most_similar_seq_length'] = df['most_similar_seq'].apply(len)\n",
    "    return df[['seq_length', 'most_similar_seq_length']]\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 加载数据\n",
    "    df = pd.read_pickle('/workspace/LLaRA/data/ref/movielens/similar_train_data.df')\n",
    "\n",
    "    # 解析序列\n",
    "    df = parse_sequences(df)\n",
    "\n",
    "    # 检查序列长度\n",
    "    lengths = check_sequence_lengths(df)\n",
    "   \n",
    "    # 计算Jaccard相似度\n",
    "    df = calculate_jaccard_similarity(df)\n",
    "\n",
    "    # 计算 nDCG\n",
    "    df = calculate_ndcg(df)\n",
    "\n",
    "    # 计算 DTW 距离\n",
    "    df = calculate_dtw_for_df(df)\n",
    "\n",
    "    # 计算平均值\n",
    "    averages = calculate_average_metrics(df)\n",
    "\n",
    "    # 输出结果\n",
    "    print('similar_train_data.df')\n",
    "    print(df[['jaccard_similarity', 'ndcg@1', 'ndcg@2', 'ndcg@3', 'dtw_distance']])\n",
    "    print(\"Average Metrics:\", averages)\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6ac96-9905-4726-9e7a-b8249bbb3004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
